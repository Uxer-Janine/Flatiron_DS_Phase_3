{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Cross-Validation\" data-toc-modified-id=\"Cross-Validation-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Cross-Validation</a></span></li><li><span><a href=\"#Using-KFolds\" data-toc-modified-id=\"Using-KFolds-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Using KFolds</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bias---Variance-Tradeoff\" data-toc-modified-id=\"Bias---Variance-Tradeoff-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Bias - Variance Tradeoff</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Hp/Documents/Flatiron/Phase 3/Flatiron_Phase_3/Notes/Statistical Learning Theory/student-mat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0      4        3      4     1     1      3        6   5   6   6  \n",
       "1      5        3      3     1     1      3        4   5   5   6  \n",
       "2      4        3      2     2     3      3       10   7   8  10  \n",
       "3      3        2      2     1     1      5        2  15  14  15  \n",
       "4      4        3      2     1     2      5        4   6  10  10  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  Medu  Fedu  traveltime  studytime  failures  famrel  freetime  \\\n",
      "0     18     4     4           2          2         0       4         3   \n",
      "1     17     1     1           1          2         0       5         3   \n",
      "2     15     1     1           1          2         3       4         3   \n",
      "3     15     4     2           1          3         0       3         2   \n",
      "4     16     3     3           1          2         0       4         3   \n",
      "..   ...   ...   ...         ...        ...       ...     ...       ...   \n",
      "390   20     2     2           1          2         2       5         5   \n",
      "391   17     3     1           2          1         0       2         4   \n",
      "392   21     1     1           1          1         3       5         5   \n",
      "393   18     3     2           3          1         0       4         4   \n",
      "394   19     1     1           1          1         0       3         2   \n",
      "\n",
      "     goout  Dalc  ...  guardian_mother  guardian_other  schoolsup_yes  \\\n",
      "0        4     1  ...                1               0              1   \n",
      "1        3     1  ...                0               0              0   \n",
      "2        2     2  ...                1               0              1   \n",
      "3        2     1  ...                1               0              0   \n",
      "4        2     1  ...                0               0              0   \n",
      "..     ...   ...  ...              ...             ...            ...   \n",
      "390      4     4  ...                0               1              0   \n",
      "391      5     3  ...                1               0              0   \n",
      "392      3     3  ...                0               1              0   \n",
      "393      1     3  ...                1               0              0   \n",
      "394      3     3  ...                0               0              0   \n",
      "\n",
      "     famsup_yes  paid_yes  activities_yes  nursery_yes  higher_yes  \\\n",
      "0             0         0               0            1           1   \n",
      "1             1         0               0            0           1   \n",
      "2             0         1               0            1           1   \n",
      "3             1         1               1            1           1   \n",
      "4             1         1               0            1           1   \n",
      "..          ...       ...             ...          ...         ...   \n",
      "390           1         1               0            1           1   \n",
      "391           0         0               0            0           1   \n",
      "392           0         0               0            0           1   \n",
      "393           0         0               0            0           1   \n",
      "394           0         0               0            1           1   \n",
      "\n",
      "     internet_yes  romantic_yes  \n",
      "0               0             0  \n",
      "1               1             0  \n",
      "2               1             0  \n",
      "3               1             1  \n",
      "4               0             0  \n",
      "..            ...           ...  \n",
      "390             0             0  \n",
      "391             1             0  \n",
      "392             0             0  \n",
      "393             1             0  \n",
      "394             1             0  \n",
      "\n",
      "[395 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "# changing categorical data into numerical data \n",
    "\n",
    "df_encoded = pd.get_dummies(df,drop_first=True)\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>...</th>\n",
       "      <th>guardian_mother</th>\n",
       "      <th>guardian_other</th>\n",
       "      <th>schoolsup_yes</th>\n",
       "      <th>famsup_yes</th>\n",
       "      <th>paid_yes</th>\n",
       "      <th>activities_yes</th>\n",
       "      <th>nursery_yes</th>\n",
       "      <th>higher_yes</th>\n",
       "      <th>internet_yes</th>\n",
       "      <th>romantic_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  Medu  Fedu  traveltime  studytime  failures  famrel  freetime  goout  \\\n",
       "0   18     4     4           2          2         0       4         3      4   \n",
       "1   17     1     1           1          2         0       5         3      3   \n",
       "2   15     1     1           1          2         3       4         3      2   \n",
       "3   15     4     2           1          3         0       3         2      2   \n",
       "4   16     3     3           1          2         0       4         3      2   \n",
       "\n",
       "   Dalc  ...  guardian_mother  guardian_other  schoolsup_yes  famsup_yes  \\\n",
       "0     1  ...                1               0              1           0   \n",
       "1     1  ...                0               0              0           1   \n",
       "2     2  ...                1               0              1           0   \n",
       "3     1  ...                1               0              0           1   \n",
       "4     1  ...                0               0              0           1   \n",
       "\n",
       "   paid_yes  activities_yes  nursery_yes  higher_yes  internet_yes  \\\n",
       "0         0               0            1           1             0   \n",
       "1         0               0            0           1             1   \n",
       "2         1               0            1           1             1   \n",
       "3         1               1            1           1             1   \n",
       "4         1               0            1           1             0   \n",
       "\n",
       "   romantic_yes  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             1  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_encoded\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define x and y \n",
    "\n",
    "x = df.drop(\"G3\",axis=1)\n",
    "y = df[\"G3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing \n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is basically what model validation is \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we train the model \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11592662,  0.08631677, -0.16737768,  0.08859282, -0.00774276,\n",
       "       -0.28578115,  0.31496242, -0.02022574,  0.18985939, -0.18550918,\n",
       "        0.05390572,  0.04402694,  0.05559269,  0.2116987 ,  0.95777208,\n",
       "        0.09381411,  0.3744096 ,  0.08261237, -0.00877173, -0.14039393,\n",
       "       -0.4632439 , -0.23719518, -0.0516432 ,  0.09915197,  0.4812421 ,\n",
       "        0.20644054, -0.29476201, -0.06829101, -0.61190072,  0.30497262,\n",
       "       -0.22169394,  0.09530352, -0.1492908 ,  0.78565167,  0.20365619,\n",
       "        0.06722228, -0.51749961, -0.23686146,  0.3753768 , -0.16820426,\n",
       "       -0.39035251])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.9970238353909995"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_\n",
    "\n",
    "# this is the base value when you have a 0 and all the variables are constant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.65664283323122\n",
      "2.3783697847961363\n",
      "0.7241341236974023\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model \n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np \n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "mse = mean_squared_error (y_test,y_pred)\n",
    "rsme = np.sqrt(mse)\n",
    "\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "\n",
    "print(mse)\n",
    "print(rsme)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for over fitting \n",
    "r2_train = model.score(x_train, y_train)\n",
    "r2_test = model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8655977464052783\n"
     ]
    }
   ],
   "source": [
    "print(r2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7241341236974023\n"
     ]
    }
   ],
   "source": [
    "print(r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = ['Train RÂ²', 'Test RÂ²']\n",
    "scores = [r2_train, r2_test]\n",
    "\n",
    "plt.bar(labels, scores, color=['blue', 'orange'])\n",
    "plt.ylabel(\"RÂ² Score\")\n",
    "plt.title(\"Train vs Test RÂ² Comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation \n",
    "We test our model on even smaller subset of our data to see if it still performs well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82263842, 0.85731278, 0.84727753, 0.81021576, 0.79418657])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold \n",
    "\n",
    "cross_val_score(model,x_train,y_train,cv=5)\n",
    "\n",
    "# DEfailt score is R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.43188383, 4.45894445, 1.29484892, 3.32464003, 3.78684952,\n",
       "       3.06085047, 3.49357183, 5.78720221, 3.11576128, 3.92658775])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# cross_val_score(model, x_train, y_train, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "cross_val_score(model, x_train, y_train, cv=10, scoring=make_scorer(mean_squared_error))\n",
    "\n",
    "# DEfailt score is R^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using KFolds \n",
    "This is a cross validation object you create that allows you to specify how the data is folded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83928841, 0.80510185, 0.7717791 , 0.82033028, 0.64953931,\n",
       "       0.8660007 , 0.88342242, 0.83607529, 0.74501594, 0.85140042])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a KFold object \n",
    "folds = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "cross_val_score(model, x_train, y_train, cv=folds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices:[  0   1   2   3   4   6   7   8  10  11  12  13  14  15  16  17  18  19\n",
      "  20  21  22  23  24  26  27  28  29  30  31  32  34  35  36  37  38  39\n",
      "  40  41  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58\n",
      "  59  61  62  64  65  66  67  68  69  70  71  72  73  74  75  77  79  80\n",
      "  81  83  84  85  86  87  88  89  90  91  92  94  95  96  97  98  99 100\n",
      " 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 138\n",
      " 140 141 142 143 144 145 147 148 149 150 151 152 153 154 155 156 157 159\n",
      " 160 161 162 164 166 167 169 170 171 172 174 175 176 177 178 181 182 183\n",
      " 184 185 186 187 188 189 190 191 192 193 194 196 197 198 199 200 201 202\n",
      " 204 205 206 207 208 209 210 211 212 213 214 215 216 217 219 220 221 222\n",
      " 223 224 225 226 227 228 229 230 231 232 233 234 235 236 238 239 240 241\n",
      " 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259\n",
      " 260 261 263 264 266 267 268 269 270 271 272 273 274 275 276 277 278 279\n",
      " 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 297 298 299\n",
      " 300 301 303 304 305 306 307 309 310 311 312 313 314 315]\n",
      "Train indices:[  0   1   2   4   5   6   8   9  10  11  12  13  14  15  16  18  19  20\n",
      "  21  22  23  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39\n",
      "  40  41  42  43  44  47  48  49  50  51  52  53  54  55  56  58  59  60\n",
      "  61  62  63  64  65  66  67  68  69  70  71  72  74  75  76  78  79  80\n",
      "  81  82  83  85  86  87  88  89  91  92  93  94  95  96  97  98  99 100\n",
      " 101 102 103 105 106 107 109 110 112 114 115 117 118 119 120 121 122 123\n",
      " 124 125 126 127 128 129 130 131 133 134 135 136 137 138 139 140 141 142\n",
      " 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160\n",
      " 161 162 163 164 165 166 167 168 169 170 171 172 173 174 176 177 178 179\n",
      " 180 181 183 184 185 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 207 208 209 210 211 212 213 214 215 216 217 218\n",
      " 219 220 222 224 226 227 228 229 230 231 232 233 234 235 236 237 239 240\n",
      " 241 242 243 244 245 246 247 248 249 250 251 252 254 255 256 257 258 259\n",
      " 260 261 262 263 264 265 266 267 268 269 270 271 273 274 275 276 278 279\n",
      " 280 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298\n",
      " 299 301 302 303 306 307 308 309 310 311 312 313 314 315]\n",
      "Train indices:[  0   1   2   3   4   5   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  23  24  25  26  27  28  29  31  32  33  34  35  36  37  38\n",
      "  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  57\n",
      "  58  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  76  77\n",
      "  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  95  96\n",
      "  97  98  99 100 102 103 104 105 106 107 108 110 111 112 113 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135\n",
      " 136 137 138 139 140 141 142 146 147 149 150 151 152 153 154 156 158 159\n",
      " 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177\n",
      " 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 194 195 196\n",
      " 197 198 199 200 201 202 203 204 205 206 207 211 212 214 215 216 217 218\n",
      " 219 220 221 222 223 224 225 226 228 229 230 231 232 233 235 236 237 238\n",
      " 239 240 241 242 243 244 245 246 247 248 249 251 252 253 254 256 257 259\n",
      " 260 261 262 263 264 265 266 267 269 270 271 272 273 274 276 277 278 279\n",
      " 280 281 282 283 284 285 286 287 288 290 291 292 293 295 296 297 298 300\n",
      " 302 303 304 305 306 307 308 309 310 311 312 313 314 315]\n",
      "Train indices:[  0   1   2   3   4   5   6   7   8   9  11  12  13  14  17  20  21  22\n",
      "  23  24  25  26  27  28  29  30  32  33  34  35  36  38  39  40  41  42\n",
      "  43  44  45  46  47  48  49  50  51  52  53  54  56  57  58  59  60  61\n",
      "  62  63  64  65  70  71  73  74  75  76  77  78  80  81  82  83  84  85\n",
      "  86  87  88  89  90  91  93  94  95  98  99 100 101 102 103 104 105 106\n",
      " 107 108 109 110 111 112 113 114 115 116 117 119 120 121 122 123 125 127\n",
      " 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145\n",
      " 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163\n",
      " 165 166 168 169 170 171 172 173 174 175 176 178 179 180 182 183 184 186\n",
      " 187 188 189 190 191 192 193 195 196 197 198 200 201 202 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 245 246 249 250 251 252 253 254 255 256 257 258 259 260 261 262\n",
      " 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280\n",
      " 281 282 283 284 286 287 288 289 290 291 292 293 294 295 296 297 299 300\n",
      " 301 302 303 304 305 306 307 308 309 310 311 312 314 315]\n",
      "Train indices:[  0   1   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55\n",
      "  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73\n",
      "  74  75  76  77  78  79  80  81  82  83  84  85  87  88  89  90  91  92\n",
      "  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110\n",
      " 111 113 114 116 118 119 120 121 122 123 124 126 127 128 130 131 132 133\n",
      " 134 135 136 137 138 139 141 142 143 144 145 146 148 149 150 151 153 155\n",
      " 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 173 174\n",
      " 175 176 177 178 179 180 181 182 183 185 186 187 188 189 190 191 192 193\n",
      " 194 195 199 200 201 203 205 206 207 208 209 210 211 212 213 214 215 216\n",
      " 217 218 220 221 222 223 224 225 226 227 230 232 233 234 235 236 237 238\n",
      " 239 240 241 242 243 244 247 248 250 251 252 253 254 255 256 257 258 259\n",
      " 260 261 262 263 264 265 268 269 270 271 272 273 274 275 276 277 278 279\n",
      " 280 281 282 283 284 285 287 288 289 290 291 293 294 295 296 298 299 300\n",
      " 301 302 303 304 305 306 307 308 309 310 312 313 314 315]\n",
      "Train indices:[  0   1   2   3   4   5   6   7   8   9  10  11  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  30  31  32  33  34  36  37  38  39\n",
      "  40  41  42  43  44  45  46  47  48  49  50  52  53  54  55  56  57  58\n",
      "  59  60  61  62  63  64  66  67  68  69  70  71  72  73  75  76  77  78\n",
      "  79  80  81  82  84  86  87  88  89  90  91  92  93  94  96  97  98  99\n",
      " 100 101 102 103 104 105 106 108 109 110 111 112 113 114 115 116 117 118\n",
      " 119 121 122 123 124 125 126 128 129 130 132 134 135 136 137 138 139 140\n",
      " 141 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 160\n",
      " 161 162 163 164 165 166 167 168 169 171 172 173 174 175 177 179 180 181\n",
      " 182 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200\n",
      " 201 202 203 204 205 206 207 208 209 210 212 213 214 215 216 217 218 219\n",
      " 221 222 223 224 225 226 227 228 229 231 232 234 235 236 237 238 240 241\n",
      " 242 243 244 245 246 247 248 249 250 251 252 253 255 257 258 259 260 262\n",
      " 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 280 281\n",
      " 282 283 285 286 287 288 289 290 292 293 294 295 296 297 298 299 300 301\n",
      " 302 303 304 305 306 307 308 309 310 311 312 313 314 315]\n",
      "Train indices:[  1   2   3   5   6   7   8   9  10  12  13  14  15  16  17  18  19  20\n",
      "  21  22  23  24  25  28  29  30  31  32  33  34  35  37  38  39  40  42\n",
      "  43  44  45  46  48  49  50  51  52  53  54  55  56  57  58  59  60  62\n",
      "  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80\n",
      "  81  82  83  84  85  86  87  88  90  91  92  93  94  95  96  97  99 101\n",
      " 102 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120\n",
      " 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 137 138 139\n",
      " 140 142 143 144 145 146 147 148 149 151 152 153 154 155 156 157 158 159\n",
      " 160 161 162 163 164 165 166 167 168 169 170 172 173 174 175 176 177 178\n",
      " 179 180 181 182 183 184 185 186 187 188 189 190 191 193 194 195 196 197\n",
      " 198 199 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216\n",
      " 217 218 219 220 221 223 225 226 227 228 229 230 231 232 233 234 235 236\n",
      " 237 238 239 241 243 245 246 247 248 249 250 251 252 253 254 255 256 257\n",
      " 258 259 261 262 263 264 265 266 267 268 269 270 272 273 274 275 276 277\n",
      " 278 279 280 281 284 285 286 288 289 290 291 292 293 294 295 296 297 298\n",
      " 299 300 301 302 303 304 305 306 307 308 310 311 313 314 315]\n",
      "Train indices:[  0   1   2   3   4   5   6   7   9  10  11  12  13  15  16  17  18  19\n",
      "  20  21  22  24  25  26  27  28  29  30  31  33  34  35  36  37  38  39\n",
      "  41  42  43  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59\n",
      "  60  61  63  65  66  67  68  69  71  72  73  74  75  76  77  78  79  80\n",
      "  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 107 108 109 111 112 113 114 115 116 117 118\n",
      " 119 120 121 124 125 126 127 129 130 131 132 133 134 136 137 139 140 141\n",
      " 142 143 144 145 146 147 148 149 150 151 152 154 155 157 158 159 160 161\n",
      " 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180\n",
      " 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198\n",
      " 199 200 201 202 203 204 205 206 208 209 210 211 212 213 214 217 218 219\n",
      " 220 221 222 223 224 225 227 228 229 230 231 233 234 235 237 238 239 240\n",
      " 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258\n",
      " 259 260 261 262 263 264 265 266 267 268 270 271 272 273 275 276 277 279\n",
      " 280 281 282 283 284 285 286 287 288 289 291 292 293 294 296 297 298 299\n",
      " 300 301 302 303 304 305 307 308 309 310 311 312 313 314 315]\n",
      "Train indices:[  0   2   3   4   5   6   7   8   9  10  11  12  14  15  16  17  18  19\n",
      "  20  21  22  23  24  25  26  27  28  29  30  31  32  33  35  36  37  38\n",
      "  40  41  42  44  45  46  47  48  50  51  54  55  56  57  58  59  60  61\n",
      "  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79\n",
      "  81  82  83  84  85  86  87  89  90  92  93  94  95  96  97  98  99 100\n",
      " 101 102 103 104 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 135 136 137 138\n",
      " 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156\n",
      " 157 158 159 160 162 163 164 165 167 168 169 170 171 172 173 174 175 176\n",
      " 177 178 179 180 181 182 183 184 185 186 187 188 189 191 192 193 194 195\n",
      " 196 197 198 199 200 202 203 204 206 207 208 209 210 211 213 214 215 216\n",
      " 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235\n",
      " 236 237 238 239 240 242 244 245 246 247 248 249 250 252 253 254 255 256\n",
      " 257 258 260 261 262 265 266 267 268 269 270 271 272 274 275 276 277 278\n",
      " 279 280 281 282 283 284 285 286 287 289 290 291 292 293 294 295 296 297\n",
      " 298 299 300 301 302 304 305 306 308 309 311 312 313 314 315]\n",
      "Train indices:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37\n",
      "  38  39  40  41  42  43  44  45  46  47  49  51  52  53  55  56  57  59\n",
      "  60  61  62  63  64  65  66  67  68  69  70  72  73  74  75  76  77  78\n",
      "  79  80  81  82  83  84  85  86  88  89  90  91  92  93  94  95  96  97\n",
      "  98 100 101 103 104 105 107 108 109 110 111 112 113 114 115 116 117 118\n",
      " 119 120 122 123 124 125 126 127 128 129 131 132 133 134 135 136 137 138\n",
      " 139 140 141 142 143 144 145 146 147 148 150 152 153 154 155 156 157 158\n",
      " 159 161 162 163 164 165 166 167 168 170 171 172 173 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 190 192 193 194 195 196 197 198 199 200 201\n",
      " 202 203 204 205 206 207 208 209 210 211 212 213 215 216 217 218 219 220\n",
      " 221 222 223 224 225 226 227 228 229 230 231 232 233 234 236 237 238 239\n",
      " 240 241 242 243 244 245 246 247 248 249 250 251 253 254 255 256 258 259\n",
      " 260 261 262 263 264 265 266 267 268 269 271 272 273 274 275 277 278 279\n",
      " 280 281 282 283 284 285 286 287 288 289 290 291 292 294 295 296 297 298\n",
      " 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313]\n"
     ]
    }
   ],
   "source": [
    "# check how the data was split \n",
    "for fold in folds.split(x_train):\n",
    "    train_indices, test_indices = fold\n",
    "    print(f\"Train indices:{train_indices}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias - Variance Tradeoff \n",
    "\n",
    "* Model Complexity: How well a model is able to explain the underlying features in a training dataset\n",
    "* Bias: High bias means a model is not able to make correct predictions and is underfitted =. \n",
    "* Variance: High variance means the model captures noise and is overfitted. \n",
    "* Underfitting: High Bias, Low variance \n",
    "* Overfitting: Low Bias, High variance \n",
    "* Optimum: Ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
